# レバテック案件スクレイピング設計書

---

## 1. このプログラムの目的

このプログラムは「レバテックフリーランス」という仕事サイトから、  
**Pythonに関係する案件を自動で集めてスプレッドシートに整理する** ためのツールです。

手作業で検索する代わりに、Pythonがブラウザを自動で操作してくれることで、  
- 案件を探す時間を短縮できる  
- 結果をスプレッドシートに整理できる  
- 将来的に自動で更新できる  

という効果があります。

---

## 2. 全体の流れ（動作のイメージ）

1. Chromeを自動で起動する  
2. レバテックの検索ページを開く  
3. 「Python」と「終了案件を除く」にチェックを入れる  
4. 「検索」ボタンをクリックする  
5. 検索結果の案件を1ページずつ読み取る（最大10ページ）  
6. 重複や条件に合わない案件を除外する  
7. スプレッドシートに結果を書き込む  

---

## 3. 使用するファイル構成

```
levtech_scraper/
├── main.py                 # 実行の入り口（プログラム全体の起動）
├── flow.py                 # 自動処理の流れをまとめる
├── chrome.py               # Chromeを開いたりURLを表示したりする
├── selenium_manager.py     # ページ内のボタンや文字を見つけて操作する
├── logger.py               # ログ（実行記録）を出力する
├── spreadsheet_manager.py  # スプレッドシートに書き込む
├── .env                    # URLなどの秘密情報を入れる
└── docs/
    └── design.md           # この設計書
```

---

## 4. クラスの役割（わかりやすく）

| クラス名 | 役割 |
|-----------|------|
| ChromeManager | Chromeを起動して、ページを開く |
| GetElement | ページの中からボタンや入力欄を探す |
| ActionElement | ボタンをクリックしたり、文字を入力したりする |
| AutoScrapingFlow | 全体の流れを管理する（司令塔） |
| SpreadsheetManager | 結果をスプレッドシートに保存する |

---

## 5. 集めるデータの内容

| 項目名 | 内容 |
|---------|------|
| タイトル | 案件の名前 |
| URL | 詳細ページのリンク |
| 最低単価 | 最低金額（円） |
| 最高単価 | 最高金額（円） |
| 平均単価 | 平均金額（円） |
| スキル | Pythonなどの使用技術 |
| 概要 | 案件の内容の一部（説明） |
| 取得日 | データを取得した日付 |

---

## 6. スプレッドシートの構成（書き込み先）

| 列 | 項目 | 内容 |
|----|------|------|
| A | タイトル | 案件のタイトル |
| B | URL | 案件ページのリンク |
| C | 最低単価 | 最低金額 |
| D | 最高単価 | 最高金額 |
| E | 平均単価 | 計算した平均金額 |
| F | スキル | 使用スキル（Pythonなど） |
| G | 概要 | 案件の内容の一部 |
| H | 登録日 | データ取得日 |

---

## 7. 処理の流れ（少し詳しく）

1. Chromeを起動  
2. .envファイルに書かれたURLを開く  
3. チェックボックスに自動でチェックを入れる  
4. 検索ボタンをクリック  
5. 案件の一覧を取得  
6. ページ送りして繰り返す（最大10ページ）  
7. 重複データを削除  
8. スプレッドシートに書き込み  
9. 終了ログを出力  

---

## 8. エラーが起きたときの動作

| 起きる可能性のある問題 | 対応方法 |
|--------------------------|-----------|
| Chromeが開かない | エラーメッセージを出して停止する |
| ボタンが見つからない | スキップして次の操作へ進む |
| ページが開けない | 3回リトライしてダメなら停止 |
| スプレッドシート書き込み失敗 | リトライまたはスキップ |

---

## 9. 使うPythonライブラリ

```
selenium
python-dotenv
gspread
oauth2client
beautifulsoup4
pandas
```

---

## 10. 開発の順番（実装ステップ）

| ステップ | 内容 | 使用ファイル |
|-----------|------|---------------|
| STEP1 | 設計と環境構築 | design.md, venv |
| STEP2 | Chrome起動とURLアクセス | chrome.py, .env |
| STEP3 | 検索条件クリック | selenium_manager.py |
| STEP4 | 案件情報の取得 | flow.py |
| STEP5 | ページ送り（10ページ分） | flow.py |
| STEP6 | データ整形と重複除外 | flow.py |
| STEP7 | スプレッドシート出力 | spreadsheet_manager.py |
| STEP8 | 全体統合とテスト | main.py, flow.py |

---

## 11. 実行のしかた

ターミナルで以下を入力する。

```
python main.py
```

ブラウザが自動で起動して、指定のサイトを開く。

---

## 12. 更新履歴

| 日付 | バージョン |
|------|-------------|
| 2025-10-25 | v1.0 |
